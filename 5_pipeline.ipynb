{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7b83e30-72a6-4a7e-b8c2-bd20891b380f",
      "metadata": {
        "id": "c7b83e30-72a6-4a7e-b8c2-bd20891b380f"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = None\n",
        "\n",
        "# Cargar el modelo\n",
        "with open(\"modelo.pkl\", 'rb') as file:\n",
        "    modelo = pickle.load(file)"
      ],
      "metadata": {
        "id": "rAca2YDbBHdM"
      },
      "id": "rAca2YDbBHdM",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predecir', methods=['POST'])\n",
        "def predict():\n",
        "    # obtener json\n",
        "    data = request.get_json(force=True)\n",
        "\n",
        "    # convertir los datos a un arreglo de Numpy\n",
        "    input_data = np.array(data['input']).reshape(1, -1)\n",
        "\n",
        "    # Hacer predicción\n",
        "    prediccion = modelo.predict(input_data)\n",
        "\n",
        "    # regresar predicción en formato json\n",
        "    return jsonify({'prediccion': int(prediccion[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H86IGKrnEBqJ",
        "outputId": "9ef4889c-c473-4e86-ee7f-e6cf9c1a0f09"
      },
      "id": "H86IGKrnEBqJ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curl -X POST http://127.0.0.1:5000/predecir -d '{\"input\": [0,0,0,0,0,0,0]}'"
      ],
      "metadata": {
        "id": "X7gRiC0NEm4y"
      },
      "id": "X7gRiC0NEm4y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"Pclass\": 0,\n",
        "  \"Sex\": 1,\n",
        "  \"Age\": 0.6159084,\n",
        "  \"SibSp\": 0,\n",
        "  \"Parch\": 0,\n",
        "  \"Fare\": 0.55547282,\n",
        "  \"Embarked\": 1,\n",
        "}"
      ],
      "metadata": {
        "id": "LV3wNXWGE2k6"
      },
      "id": "LV3wNXWGE2k6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----"
      ],
      "metadata": {
        "id": "B9w_bnjkE46a"
      },
      "id": "B9w_bnjkE46a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder # <------------------ Esto es nuevo :)\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.compose import ColumnTransformer # <------------------ Esto es nuevo :)\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline # <------------------ Esto es nuevo :)\n",
        "\n",
        "# Modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "\n",
        "# Métricas de evaluación\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Para guardar el modelo\n",
        "import pickle"
      ],
      "metadata": {
        "id": "PW-QqA3YE7AS"
      },
      "id": "PW-QqA3YE7AS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('titanic_clean.csv')"
      ],
      "metadata": {
        "id": "QBU2dnOnE8rT"
      },
      "id": "QBU2dnOnE8rT",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir preprocesamiento\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(), ['Sex', 'Embarked']),  # OneHotEncoder para columnas categóricas\n",
        "        ('age', QuantileTransformer(output_distribution='normal', n_quantiles=500), ['Age']),\n",
        "        ('fare', QuantileTransformer(output_distribution='normal', n_quantiles=500), ['Fare'])\n",
        "    ],\n",
        "    remainder='passthrough'  # Mantener otras columnas sin cambios\n",
        ")"
      ],
      "metadata": {
        "id": "VXRSfpqiE-BS"
      },
      "id": "VXRSfpqiE-BS",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los modelos y sus respectivos hiperparámetros para GridSearch\n",
        "modelos = {\n",
        "    'Regresión Logística': {\n",
        "        'modelo': LogisticRegression(),\n",
        "        'parametros': {\n",
        "            'model__C': [0.01, 0.1, 1, 10, 100],\n",
        "            'model__penalty': ['l1', 'l2'],\n",
        "            'model__solver': ['liblinear', 'saga'],\n",
        "            'model__max_iter': [100, 500, 1000]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Vectores de Soporte': {\n",
        "        'modelo': SVC(),\n",
        "        'parametros': {\n",
        "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "            'model__C': [0.1, 1, 10]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Árbol de Decisión': {\n",
        "        'modelo': DecisionTreeClassifier(),\n",
        "        'parametros': {\n",
        "            'model__splitter': ['best', 'random'],\n",
        "            'model__max_depth': [None, 1, 2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Bosques Aleatorios': {\n",
        "        'modelo': RandomForestClassifier(),\n",
        "        'parametros': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3, 4],\n",
        "            'model__max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Gradient Boosting': {\n",
        "        'modelo': GradientBoostingClassifier(),\n",
        "        'parametros': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador AdaBoost': {\n",
        "        'modelo': AdaBoostClassifier(),\n",
        "        'parametros': {\n",
        "            'model__n_estimators': [10, 100]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador K-Nearest Neighbors': {\n",
        "        'modelo': KNeighborsClassifier(),\n",
        "        'parametros': {\n",
        "            'model__n_neighbors': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador XGBoost': {\n",
        "        'modelo': XGBClassifier(),\n",
        "        'parametros': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador LGBM': {\n",
        "        'modelo': LGBMClassifier(),\n",
        "        'parametros': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3],\n",
        "            'model__learning_rate': [0.1, 0.2, 0.3],\n",
        "            'model__verbose': [-1]\n",
        "        }\n",
        "    },\n",
        "    'GaussianNB': {\n",
        "        'modelo': GaussianNB(),\n",
        "        'parametros': {}\n",
        "    },\n",
        "    'Clasificador Naive Bayes': {\n",
        "        'modelo': BernoulliNB(),\n",
        "        'parametros': {\n",
        "            'model__alpha': [0.1, 1.0, 10.0]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "pYr7RFxDFEJb"
      },
      "id": "pYr7RFxDFEJb",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# División de datos\n",
        "X = df.drop(['Survived'], axis=1)\n",
        "y = df['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
      ],
      "metadata": {
        "id": "toJAB2GXFGET"
      },
      "id": "toJAB2GXFGET",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar variables para almacenar los puntajes de los modelos y el mejor estimador\n",
        "puntajes_modelos = []\n",
        "mejor_precision = 0\n",
        "mejor_estimador = None\n",
        "mejor_modelo = None\n",
        "estimadores = {}"
      ],
      "metadata": {
        "id": "_XCxXPOfFHJD"
      },
      "id": "_XCxXPOfFHJD",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterar sobre cada modelo y sus hiperparámetros\n",
        "for nombre, info_modelo in modelos.items():\n",
        "    # Crear pipeline para el modelo\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('scaler', MinMaxScaler()),  # MinMaxScaler se aplica a todas las columnas después del preprocesamiento\n",
        "        ('model', info_modelo['modelo'])  # Modelo placeholder\n",
        "    ])\n",
        "\n",
        "    # Inicializar GridSearchCV con el pipeline y los hiperparámetros\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_grid=info_modelo['parametros'],\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        verbose=0,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    # Ajustar GridSearchCV con los datos de entrenamiento\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones con el modelo ajustado\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "\n",
        "    # Calcular la precisión de las predicciones\n",
        "    precision = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Almacenar los resultados del modelo\n",
        "    puntajes_modelos.append({\n",
        "        'Modelo': nombre,\n",
        "        'Precisión': precision\n",
        "    })\n",
        "\n",
        "    estimadores[nombre] = grid_search.best_estimator_\n",
        "\n",
        "    # Actualizar el mejor modelo si la precisión actual es mayor que la mejor precisión encontrada\n",
        "    if precision > mejor_precision:\n",
        "        mejor_modelo = nombre\n",
        "        mejor_precision = precision\n",
        "        mejor_estimador = grid_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQV6Re0mFJKD",
        "outputId": "fdde19af-8771-46b2-c03f-84b66c2f4688"
      },
      "id": "sQV6Re0mFJKD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir los resultados a un DataFrame para una mejor visualización\n",
        "metricas = pd.DataFrame(puntajes_modelos).sort_values('Precisión', ascending=False)\n",
        "\n",
        "# Imprimir el rendimiento de los modelos de clasificación\n",
        "print(\"Rendimiento de los modelos de clasificación\")\n",
        "print(metricas.round(2))\n",
        "\n",
        "# Imprimir el mejor modelo y su precisión\n",
        "print('---------------------------------------------------')\n",
        "print(\"MEJOR MODELO DE CLASIFICACIÓN\")\n",
        "print(f\"Modelo: {mejor_modelo}\")\n",
        "print(f\"Precisión: {mejor_precision:.2f}\")\n",
        "\n",
        "# Guardar el mejor modelo con pickle\n",
        "with open('pipeline.pkl', 'wb') as archivo_estimador:\n",
        "    pickle.dump(mejor_estimador, archivo_estimador)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8e8mZulFS67",
        "outputId": "3afed409-8193-45e5-cd14-525a0906a4fd"
      },
      "id": "x8e8mZulFS67",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendimiento de los modelos de clasificación\n",
            "                                 Modelo  Precisión\n",
            "6      Clasificador K-Nearest Neighbors       0.83\n",
            "8                     Clasificador LGBM       0.82\n",
            "4     Clasificador de Gradient Boosting       0.82\n",
            "3    Clasificador de Bosques Aleatorios       0.82\n",
            "5                 Clasificador AdaBoost       0.81\n",
            "0                   Regresión Logística       0.81\n",
            "1   Clasificador de Vectores de Soporte       0.81\n",
            "7                  Clasificador XGBoost       0.81\n",
            "2     Clasificador de Árbol de Decisión       0.80\n",
            "9                            GaussianNB       0.79\n",
            "10             Clasificador Naive Bayes       0.78\n",
            "---------------------------------------------------\n",
            "MEJOR MODELO DE CLASIFICACIÓN\n",
            "Modelo: Clasificador K-Nearest Neighbors\n",
            "Precisión: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "with open('pipeline.pkl', 'rb') as archivo_modelo:\n",
        "    modelo = pickle.load(archivo_modelo)\n",
        "\n",
        "@app.route('/predecir', methods=['POST'])\n",
        "def predecir():\n",
        "    # Obtener los datos de la solicitud\n",
        "    data = request.get_json()\n",
        "\n",
        "    # Crear un DataFrame de pandas a partir del JSON\n",
        "    input_data = pd.DataFrame([data])\n",
        "\n",
        "    # Hacer la predicción usando el modelo que tiene el pipeline que hará la transformación\n",
        "    prediccion = modelo.predict(input_data)\n",
        "\n",
        "    # Devolver la predicción como JSON\n",
        "    output = {'Survived': int(prediccion[0])}\n",
        "\n",
        "    return jsonify(output)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "QmqSI9tWGG1l"
      },
      "id": "QmqSI9tWGG1l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}