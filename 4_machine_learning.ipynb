{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c060b11a-6a02-4054-9075-6346654514ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c060b11a-6a02-4054-9075-6346654514ff",
        "outputId": "54e7e395-547f-454b-e4c6-2a70b62b9755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas de X después de la codificación:\n",
            "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
            "0       3  22.0      1      0   7.2500      True       False        True\n",
            "1       1  38.0      1      0  71.2833     False       False       False\n",
            "2       3  26.0      0      0   7.9250     False       False        True\n",
            "3       1  35.0      1      0  53.1000     False       False        True\n",
            "4       3  35.0      0      0   8.0500      True       False        True\n",
            "\n",
            "Tipos de datos de las columnas:\n",
            "Pclass          int64\n",
            "Age           float64\n",
            "SibSp           int64\n",
            "Parch           int64\n",
            "Fare          float64\n",
            "Sex_male         bool\n",
            "Embarked_Q       bool\n",
            "Embarked_S       bool\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "\n",
        "# 1. Cargar los datos\n",
        "df = pd.read_csv(\"titanic_clean.csv\")\n",
        "\n",
        "# 2. Separar la característica objetivo (y) y las características de entrada (X)\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "# 3. Aplicar One-Hot Encoding a las columnas categóricas (Sex y Embarked)\n",
        "# Esto convierte 'male'/'female' en columnas binarias como 'Sex_male' y 'Sex_female'.\n",
        "X_encoded = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "# 4. Dividir los datos\n",
        "# Ya no es necesario usar .values aquí, scikit-learn puede manejar DataFrames/arrays de NumPy.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verificar las primeras filas de X_encoded para confirmar la codificación\n",
        "print(\"Columnas de X después de la codificación:\")\n",
        "print(X_encoded.head())\n",
        "print(\"\\nTipos de datos de las columnas:\")\n",
        "print(X_encoded.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "X_train = X_train.values  # Convertir a NumPy array\n",
        "y_train = y_train.values  # Convertir a NumPy array\n",
        "X_test = X_test.values    # Convertir a NumPy array\n",
        "y_test = y_test.values    # Convertir a NumPy array"
      ],
      "metadata": {
        "id": "QF78VLG2tqzx"
      },
      "id": "QF78VLG2tqzx",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelos = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'model__C': [0.1],\n",
        "            'model__max_iter': [1000]\n",
        "        }\n",
        "    },\n",
        "    'Support Vector Classifier': {\n",
        "        'model': SVC(),\n",
        "        'params': {\n",
        "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "            'model__C': [0.1, 1, 10]\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree Classifier': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {\n",
        "            'model__splitter': ['best', 'random'],\n",
        "            'model__max_depth': [None, 1, 2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    'Random Forest Classifier': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3, 4],\n",
        "            'model__max_features': ['auto', 'sqrt', 'log2']\n",
        "        }\n",
        "    },\n",
        "    'Gradient Boosting Classifier': {\n",
        "        'model': GradientBoostingClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    'AdaBoost Classifier': {\n",
        "        'model': AdaBoostClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [10, 100]\n",
        "        }\n",
        "    },\n",
        "    'K-Nearest Neighbors Classifier': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'params': {\n",
        "            'model__n_neighbors': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'XGBoost Classifier': {\n",
        "        'model': XGBClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3]\n",
        "        }\n",
        "    },\n",
        "    'LGBM Classifier': {\n",
        "        'model': LGBMClassifier(),\n",
        "        'params': {\n",
        "            'model__n_estimators': [10, 100],\n",
        "            'model__max_depth': [None, 1, 2, 3],\n",
        "            'model__learning_rate': [0.1, 0.2, 0.3],\n",
        "            'model__verbose': [-1]\n",
        "        }\n",
        "    },\n",
        "    'GaussianNB': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {}\n",
        "    },\n",
        "    'Naive Bayes Classifier': {\n",
        "        'model': BernoulliNB(),\n",
        "        'params': {\n",
        "            'model__alpha': [0.1, 1.0, 10.0]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "G4o6Ewnztsq6"
      },
      "id": "G4o6Ewnztsq6",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los modelos y sus respectivos hiperparámetros para GridSearch\n",
        "modelos = {\n",
        "    'Regresión Logística': {\n",
        "        'modelo': LogisticRegression(),\n",
        "        'parametros': {\n",
        "            'C': [0.01, 0.1, 1, 10, 100],\n",
        "            'penalty': ['l1', 'l2'],\n",
        "            'solver': ['liblinear', 'saga'],\n",
        "            'max_iter': [100, 500, 1000]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Vectores de Soporte': {\n",
        "        'modelo': SVC(),\n",
        "        'parametros': {\n",
        "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "            'C': [0.1, 1, 10]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Árbol de Decisión': {\n",
        "        'modelo': DecisionTreeClassifier(),\n",
        "        'parametros': {\n",
        "            'splitter': ['best', 'random'],\n",
        "            'max_depth': [None, 1, 2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Bosques Aleatorios': {\n",
        "        'modelo': RandomForestClassifier(),\n",
        "        'parametros': {\n",
        "            'n_estimators': [10, 100],\n",
        "            'max_depth': [None, 1, 2, 3, 4],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador de Gradient Boosting': {\n",
        "        'modelo': GradientBoostingClassifier(),\n",
        "        'parametros': {\n",
        "            'n_estimators': [10, 100],\n",
        "            'max_depth': [None, 1, 2, 3, 4]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador AdaBoost': {\n",
        "        'modelo': AdaBoostClassifier(),\n",
        "        'parametros': {\n",
        "            'n_estimators': [10, 100]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador K-Nearest Neighbors': {\n",
        "        'modelo': KNeighborsClassifier(),\n",
        "        'parametros': {\n",
        "            'n_neighbors': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador XGBoost': {\n",
        "        'modelo': XGBClassifier(),\n",
        "        'parametros': {\n",
        "            'n_estimators': [10, 100],\n",
        "            'max_depth': [None, 1, 2, 3]\n",
        "        }\n",
        "    },\n",
        "    'Clasificador LGBM': {\n",
        "        'modelo': LGBMClassifier(),\n",
        "        'parametros': {\n",
        "            'n_estimators': [10, 100],\n",
        "            'max_depth': [None, 1, 2, 3],\n",
        "            'learning_rate': [0.1, 0.2, 0.3],\n",
        "            'verbose': [-1]\n",
        "        }\n",
        "    },\n",
        "    'GaussianNB': {\n",
        "        'modelo': GaussianNB(),\n",
        "        'parametros': {}\n",
        "    },\n",
        "    'Clasificador Naive Bayes': {\n",
        "        'modelo': BernoulliNB(),\n",
        "        'parametros': {\n",
        "            'alpha': [0.1, 1.0, 10.0]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Inicializar variables para almacenar los puntajes de los modelos y el mejor estimador\n",
        "puntajes_modelos = []\n",
        "mejor_precision = 0\n",
        "mejor_estimador = None\n",
        "mejor_modelo = None\n",
        "estimadores = {}\n",
        "\n",
        "# Iterar sobre cada modelo y sus hiperparámetros\n",
        "for nombre, info_modelo in modelos.items():\n",
        "    # Inicializar GridSearchCV con el modelo y los hiperparámetros\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=info_modelo['modelo'],\n",
        "        param_grid=info_modelo['parametros'],\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        verbose=0,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    # Ajustar GridSearchCV con los datos de entrenamiento\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones con el modelo ajustado\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "\n",
        "    # Calcular la precisión de las predicciones\n",
        "    precision = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Almacenar los resultados del modelo\n",
        "    puntajes_modelos.append({\n",
        "        'Modelo': nombre,\n",
        "        'Precisión': precision\n",
        "    })\n",
        "\n",
        "    estimadores[nombre] = grid_search.best_estimator_\n",
        "\n",
        "    # Actualizar el mejor modelo si la precisión actual es mayor que la mejor precisión encontrada\n",
        "    if precision > mejor_precision:\n",
        "        mejor_modelo = nombre\n",
        "        mejor_precision = precision\n",
        "        mejor_estimador = grid_search.best_estimator_\n",
        "\n",
        "# Convertir los resultados a un DataFrame para una mejor visualización\n",
        "metricas = pd.DataFrame(puntajes_modelos).sort_values('Precisión', ascending=False)\n",
        "\n",
        "# Imprimir el rendimiento de los modelos de clasificación\n",
        "print(\"Rendimiento de los modelos de clasificación\")\n",
        "print(metricas.round(2))\n",
        "\n",
        "# Imprimir el mejor modelo y su precisión\n",
        "print('---------------------------------------------------')\n",
        "print(\"MEJOR MODELO DE CLASIFICACIÓN\")\n",
        "print(f\"Modelo: {mejor_modelo}\")\n",
        "print(f\"Precisión: {mejor_precision:.2f}\")"
      ],
      "metadata": {
        "id": "bFW_HEQMtywj",
        "outputId": "c7ef2a88-e76e-4f45-8aa7-7ef2d13b69fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bFW_HEQMtywj",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendimiento de los modelos de clasificación\n",
            "                                 Modelo  Precisión\n",
            "8                     Clasificador LGBM       0.81\n",
            "7                  Clasificador XGBoost       0.81\n",
            "4     Clasificador de Gradient Boosting       0.81\n",
            "3    Clasificador de Bosques Aleatorios       0.80\n",
            "5                 Clasificador AdaBoost       0.79\n",
            "0                   Regresión Logística       0.79\n",
            "2     Clasificador de Árbol de Decisión       0.79\n",
            "1   Clasificador de Vectores de Soporte       0.78\n",
            "10             Clasificador Naive Bayes       0.78\n",
            "9                            GaussianNB       0.77\n",
            "6      Clasificador K-Nearest Neighbors       0.70\n",
            "---------------------------------------------------\n",
            "MEJOR MODELO DE CLASIFICACIÓN\n",
            "Modelo: Clasificador de Gradient Boosting\n",
            "Precisión: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto ya lo tenemos importado. Lo ponemos nuevamente nada más de referencia\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Creamos el modelo de regresión logística\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizamos predicciones con el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluamos el modelo usando precisión\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precisión del modelo: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "nUTgkdw9t0mY",
        "outputId": "3c769e39-e097-4f73-e267-9dee5b3cbc9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nUTgkdw9t0mY",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(\n",
        "    C=0.5,                  # Valor de regularización\n",
        "    penalty='l2',            # Tipo de penalización (l2 es la regularización Ridge)\n",
        "    solver='lbfgs',         # Algoritmo de optimización\n",
        "    max_iter=200,           # Número máximo de iteraciones\n",
        "    class_weight='balanced' # Ajustar pesos de las clases\n",
        ")\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precisión del modelo: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "IxzqkpeBwR72",
        "outputId": "dd4a0299-872a-4cab-83f7-639d5d3711ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IxzqkpeBwR72",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar GridSearchCV con los datos de entrenamiento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones con el modelo ajustado\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calcular la precisión de las predicciones\n",
        "precision = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Almacenar los resultados del modelo\n",
        "puntajes_modelos.append({\n",
        "    'Modelo': nombre,\n",
        "    'Precisión': precision\n",
        "})\n",
        "\n",
        "estimadores[nombre] = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "RXDj-MDYwtqd"
      },
      "id": "RXDj-MDYwtqd",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir los resultados a un DataFrame para una mejor visualización\n",
        "metricas = pd.DataFrame(puntajes_modelos).sort_values('Precisión', ascending=False)\n",
        "\n",
        "# Imprimir el rendimiento de los modelos de clasificación\n",
        "print(\"Rendimiento de los modelos de clasificación\")\n",
        "print(metricas.round(2))\n",
        "\n",
        "# Imprimir el mejor modelo y su precisión\n",
        "print('---------------------------------------------------')\n",
        "print(\"MEJOR MODELO DE CLASIFICACIÓN\")\n",
        "print(f\"Modelo: {mejor_modelo}\")\n",
        "print(f\"Precisión: {mejor_precision:.2f}\")"
      ],
      "metadata": {
        "id": "dW7x7WtxwqJW",
        "outputId": "568c66b2-2800-4820-ad92-8a1175236d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dW7x7WtxwqJW",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendimiento de los modelos de clasificación\n",
            "                                 Modelo  Precisión\n",
            "7                  Clasificador XGBoost       0.81\n",
            "8                     Clasificador LGBM       0.81\n",
            "4     Clasificador de Gradient Boosting       0.81\n",
            "3    Clasificador de Bosques Aleatorios       0.80\n",
            "0                   Regresión Logística       0.79\n",
            "2     Clasificador de Árbol de Decisión       0.79\n",
            "5                 Clasificador AdaBoost       0.79\n",
            "1   Clasificador de Vectores de Soporte       0.78\n",
            "11             Clasificador Naive Bayes       0.78\n",
            "10             Clasificador Naive Bayes       0.78\n",
            "9                            GaussianNB       0.77\n",
            "6      Clasificador K-Nearest Neighbors       0.70\n",
            "---------------------------------------------------\n",
            "MEJOR MODELO DE CLASIFICACIÓN\n",
            "Modelo: Clasificador de Gradient Boosting\n",
            "Precisión: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('modelo.pkl', 'wb') as archivo_estimador:\n",
        "    pickle.dump(mejor_estimador, archivo_estimador)"
      ],
      "metadata": {
        "id": "emWpQ9UTw4DW"
      },
      "id": "emWpQ9UTw4DW",
      "execution_count": 36,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}